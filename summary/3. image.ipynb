{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 이진분류_콘크리트크랙"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 전처리, 학습\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forlder_path = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 필요할 진 모르겠는 코드.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(folder_path + '...images.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test 이미지가 들어있는 폴더의 경로\n",
    "train = '...images/train'\n",
    "test = '...images/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지가 분류되어 있지 않고, 파일명에 기입되어 있는 경우 사용하는 코드\n",
    "if not os.path.exists('IMAGE'):\n",
    "    os.mkdir('IMAGE')\n",
    "if not os.path.exists('IMAGE/Negative'):\n",
    "    os.mkdir('IMAGE/Negative')\n",
    "if not os.path.exists('IMAGE/Positive'):\n",
    "    os.mkdir('IMAGE/Positive')\n",
    "\n",
    "count = 0\n",
    "# 파일명 예시: 0_0_0_20161219140623097_Negative.jpg or 0_0_0_20161219140523931_Positive.jpg\n",
    "for filename in os.listdir(train):\n",
    "    if filename.endswith('.jpg'):\n",
    "        label = filename.split(\"_\")[-1].split(\".\")[0]\n",
    "        \n",
    "        if label == \"Negative\":\n",
    "            # 현재 폴더에서 Negative 폴더로 파일 복사\n",
    "            shutil.copy(os.path.join(train, filename), os.path.join('IMAGE/Negative', filename))\n",
    "        elif label == \"Positive\":\n",
    "            # 현재 폴더에서 Positive 폴더로 파일 복사\n",
    "            shutil.copy(os.path.join(train, filename), os.path.join('IMAGE/Positive', filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 개수 확인 !! 폴더 경로 수정 필요\n",
    "!ls -l ./IMAGE/Negative/ | grep jpg | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 개수 확인 !! 폴더 경로 수정 필요\n",
    "!ls -l ./IMAGE/Positive/ | grep jpg | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 파일 하나 확인\n",
    "path = 'IMAGE/Positive/' + os.listdir('IMAGE/Positive')[1]\n",
    "print('path:', path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfile = tf.io.read_file(path)\n",
    "image = tf.io.decode_image(gfile, dtype=tf.float32)\n",
    "print('image.shape:', image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageDataGenerator: 이미지 데이터에 대해 scaling, augmentation, validattion_split 전처리 기능 수행\n",
    "# flow_from_directory: 실제 이미지 데이터를 읽고 배치, 셔플하고 labeling 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1개 IMAGE 폴더로 Train, Test dataset으로 나눠야 하므로, validation_split 사용\n",
    "# Data augmentation(이미지 변형을 통한 데이터 증강)을 사용하지 않음\n",
    "# validation 데이터 사이즈 입력 : validation_split=0.2 --> 20%\n",
    "# (주의점) MobileNetV2에 인풋으로 사용하기 전에 전 처리하는 코드가 preprocess_input으로 함수화 되어 있습니다. 따라서 그대로 사용하시면 됩니다.\n",
    "# 그래서 rescale 수행하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datagen = ImageDataGenerator(\n",
    "    # rescale=1./255,\n",
    "    validation_split=0.2, # MobileNetV2의 경우, 아래 preprocess_input을 호출해서 리스케일 함\n",
    "    preprocessing_function=preprocess_input\n",
    "    # rotation_range=30,\n",
    "    # width_shift_range=0.1,\n",
    "    # height_shift_range=0.1,\n",
    "    # shear_range=0.1,\n",
    "    # zoom_range=0.1,\n",
    "    # horizontal_flip=True,\n",
    "    # fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 폴더 내 데이터를 읽고, 배치, 셔플하고 라벨링 수행\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "learning_rate = 0.001\n",
    "dropout_rate = 0.5\n",
    "\n",
    "input_shape = (224, 224, 3) # MovileNetV2의 기본 입력값을 위해 사이즈 변경\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 폴더 내의 데이터  읽고 배치 , 셔플하고 labeling 수행\n",
    "# 실제로 1개 IMAGE 폴더에서 Train 32000건, Test 8000건 dataset 만듬\n",
    "# 2개 Class에 대한 라벨링(라벨인코딩,원핫인코딩) 수행\n",
    "# MobileNetV2은 [96, 128, 160, 192, 224] 사이즈만 지원하므로 flow_from_directory 함수에서 사이즈 변경함\n",
    "# subset = 'training' --> training_generator 생성\n",
    "# subset = 'validation' --> test_generator 생성\n",
    "\n",
    "# IMAGE 폴더 밑에 .ipynb_checkpoints 폴더 있을경우 폴더 삭제\n",
    "#!rm -rf ./IMAGE/.ipynb_checkpoints\n",
    "\n",
    "training_generator = image_datagen.flow_from_directory(\n",
    "    './IMAGE', # 데이터 저장 경로? flow_from_directory를 써서 카테고리 별로 경로를 구분하지 않아도 됨\n",
    "    batch_size=batch_size,\n",
    "    target_size=(224, 224),\n",
    "    class_mode='categorical', # 이진분류이긴 한데... 이상하다고 다중분류 적긴 하심 ( 원핫코드? 가 나와서.. 카테고리가 맞다고 하심 )\n",
    "    shuffle=True,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "test_generator = image_datagen.flow_from_directory(\n",
    "    './IMAGE',\n",
    "    batch_size=batch_size,\n",
    "    target_size=(224, 224),\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 훈련된 모델 MobileNet V2에서 기본 모델을 생성합니다.\n",
    "# 아래와 같은 형식을 Transfer Learning 사용하며 됩니다. 우리는 그냥 불러다 사용할줄 알면 됩니다.\n",
    "\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3), weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobieNet V2 베이스 모델 고정하기\n",
    "base_model.trainble = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 구축\n",
    "x = base_model.output\n",
    "\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x) # GlobalAveragePooling2D: 3차원 텐서를 1차원으로 변환\n",
    "output = tf.keras.layers.Dense(num_classes, activation='softmax')(x) # num_classes: 2\n",
    "\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),  # Optimization\n",
    "              loss='categorical_crossentropy',  # Loss Function\n",
    "              metrics=['accuracy'])             # Metrics / Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=30)\n",
    "\n",
    "checkpoint_path = 'my_checkpoint.ckpt.weights.h5'\n",
    "checkpoint = ModelCheckPoint(\n",
    "    filepath = checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "lrReducer = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습\n",
    "history = model.fit(\n",
    "    training_generator,\n",
    "    validation_data=test_generator,\n",
    "    epochs=num_epochs, # num_epochs: 10\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[es, checkpoint, lrReducer]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) 결과 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"01073002902_3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 폴더의 파일명으로 csv의 target column 만들기\n",
    "target = []\n",
    "result = []\n",
    "\n",
    "for item in os.listdir(test): # test 데이터 경로\n",
    "    target.append(item.split(\".\")[0]) # 확장자를 제외한 파일명만 추출\n",
    "\n",
    "final = pd.DataFrame({\"target\": target, \"result\": result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "answer_class = {0: 'Negative', 1: 'Positive'}\n",
    "right = 0\n",
    "total = 0\n",
    "\n",
    "for image, label in zip(final['target'], final['result']):\n",
    "    total += 1\n",
    "    test_image_path = os.path.join(test, image + '.jpg')\n",
    "    img = load_img(test_image_path, target_size=(224, 224)) # 파일 변환 사이즈만 알려주면 됨\n",
    "    img_array = img_to_array(img) # 읽은 이미지를 Numpy 배열로변환 (224, 224, 3) 크기.\n",
    "    img_array = np.expand_dims(img_array, axis=0) # 배열 차원 확장 (1, 224, 224, 3)\n",
    "\n",
    "    # 이미지 데이터 전처리\n",
    "    img_array = preprocess_input(img_array)\n",
    "\n",
    "    # 예측\n",
    "    predictions = model.predict(img_array)\n",
    "    print(predictions)\n",
    "\n",
    "    # 예측 결과\n",
    "    predicted_class = np.argmax(predictions, axis=1)\n",
    "    confidence = np.max(predictions, axis=1)\n",
    "\n",
    "    # 클래스 인덱스를 클래스명으로 변환\n",
    "    pred = answer_class[predicted_class[0]]\n",
    "    result.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['result'] = result\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('01073002902_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 다중분류_꽃사진분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 전처리, 학습\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(folder_path + '...images.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test 이미지가 들어있는 폴더의 경로\n",
    "train = '...images/train'\n",
    "test = '...images/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지가 분류되어 있지 않고, 파일명에 기입되어 있는 경우 사용하는 코드\n",
    "if not os.path.exists('IMAGE'):\n",
    "    os.mkdir('IMAGE')\n",
    "if not os.path.exists('IMAGE/daisy'):\n",
    "    os.mkdir('IMAGE/daisy')\n",
    "if not os.path.exists('IMAGE/dandelion'):\n",
    "    os.mkdir('IMAGE/dandelion')\n",
    "if not os.path.exists('IMAGE/tulips'):\n",
    "    os.mkdir('IMAGE/tulips')\n",
    "if not os.path.exists('IMAGE/roses'):\n",
    "    os.mkdir('IMAGE/roses')\n",
    "if not os.path.exists('IMAGE/sunflowers'):\n",
    "    os.mkdir('IMAGE/sunflowers')\n",
    "\n",
    "for filename in os.listdir(train):\n",
    "    if filename.endswith('.jpg'):\n",
    "        label=filename.split(\"_\")[-1].split(\".\")[0]\n",
    "        if(label==\"daisy\"):\n",
    "          shutil.copy(os.path.join(train, filename), os.path.join(\"IMAGE/daisy\", filename))\n",
    "        elif(label==\"dandelion\"):\n",
    "          shutil.copy(os.path.join(train, filename), os.path.join(\"IMAGE/dandelion\", filename))\n",
    "        elif(label==\"tulips\"):\n",
    "          shutil.copy(os.path.join(train, filename), os.path.join(\"IMAGE/tulips\", filename))\n",
    "        elif(label==\"roses\"):\n",
    "          shutil.copy(os.path.join(train, filename), os.path.join(\"IMAGE/roses\", filename))\n",
    "        elif(label==\"sunflowers\"):\n",
    "          shutil.copy(os.path.join(train, filename), os.path.join(\"IMAGE/sunflowers\", filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# daisy 폴더 안의 이미지 개수 !! 폴더 경로 수정 필요\n",
    "!ls -l IMAGE/daisy | grep jpg | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 패스 지정\n",
    "img_path = 'IMAGE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datagen = ImageDataGenerator(\n",
    "    # rescale=1./255,\n",
    "    validation_split=0.2, # MobileNetV2의 경우, 아래 preprocess_input을 호출해서 리스케일 함\n",
    "    preprocessing_function=preprocess_input\n",
    "    # rotation_range=30,\n",
    "    # width_shift_range=0.1,\n",
    "    # height_shift_range=0.1,\n",
    "    # shear_range=0.1,\n",
    "    # zoom_range=0.1,\n",
    "    # horizontal_flip=True,\n",
    "    # fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class 이름 및 번호 매핑 확인\n",
    "print(training_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 확인\n",
    "batch_samples = next(iter(training_generator))\n",
    "\n",
    "print('One Hot Encoding : ',batch_samples[1][0]) #label 배치의 첫번째 값\n",
    "print(batch_samples[0][0].shape)  #이미지 배치의 첫번째 이미지\n",
    "plt.imshow(batch_samples[0][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 크기 확인\n",
    "print(batch_samples[0].shape)\n",
    "print(batch_samples[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 4\n",
    "batch_size =32\n",
    "\n",
    "learning_rate = 0.001\n",
    "dropout_rate = 0.5\n",
    "\n",
    "input_shape = (224, 224, 3)  # 사이즈 확인\n",
    "num_classes = 5    #  다섯 가지의 꽃 종류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE 폴더 밑에 .ipynb_checkpoints 폴더 있을경우 폴더 삭제\n",
    "#!rm -rf ./IMAGE/.ipynb_checkpoints\n",
    "\n",
    "training_generator = image_datagen.flow_from_directory(\n",
    "    img_path, # 데이터 저장 경로? flow_from_directory를 써서 카테고리 별로 경로를 구분하지 않아도 됨\n",
    "    batch_size=batch_size,\n",
    "    target_size=(224, 224),\n",
    "    class_mode='categorical', # 이진분류이긴 한데... 이상하다고 다중분류 적긴 하심 ( 원핫코드? 가 나와서.. 카테고리가 맞다고 하심 )\n",
    "    shuffle=True,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "test_generator = image_datagen.flow_from_directory(\n",
    "    img_path,\n",
    "    batch_size=batch_size,\n",
    "    target_size=(224, 224),\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 훈련된 모델 MobileNet V2에서 기본 모델을 생성합니다.\n",
    "# 아래와 같은 형식을 Transfer Learning 사용하며 됩니다. 우리는 그냥 불러다 사용할줄 알면 됩니다.\n",
    "\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3), weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobieNet V2 베이스 모델 고정하기\n",
    "base_model.trainble = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 구축\n",
    "x = base_model.output\n",
    "\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x) # GlobalAveragePooling2D: 3차원 텐서를 1차원으로 변환\n",
    "output = tf.keras.layers.Dense(num_classes, activation='softmax')(x) # num_classes:5\n",
    "\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),  # Optimization\n",
    "              loss='categorical_crossentropy',  # Loss Function\n",
    "              metrics=['accuracy'])             # Metrics / Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=30)\n",
    "\n",
    "checkpoint_path = 'my_checkpoint.ckpt.weights.h5'\n",
    "checkpoint = ModelCheckPoint(\n",
    "    filepath = checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "lrReducer = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습\n",
    "history = model.fit(\n",
    "    training_generator,\n",
    "    validation_data=test_generator,\n",
    "    epochs=num_epochs, # num_epochs: 4\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[es, checkpoint, lrReducer]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) 그래프 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Model Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (6) 결과 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"01073002902_3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 폴더의 파일명으로 csv의 target column 만들기\n",
    "target = []\n",
    "result = []\n",
    "\n",
    "for item in os.listdir(test): # test 데이터 경로\n",
    "    target.append(item.split(\".\")[0]) # 확장자를 제외한 파일명만 추출\n",
    "\n",
    "final = pd.DataFrame({\"target\": target, \"result\": result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "answer_class = {0: 'daisy', 1: 'dandelion', 2: 'roses', 3: 'sunflowers', 4: 'tulips'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "right = 0\n",
    "total = 0\n",
    "\n",
    "for image, label in zip(final['target'], final['result']):\n",
    "    total += 1\n",
    "    test_image_path = os.path.join(test, image + '.jpg')\n",
    "    img = load_img(test_image_path, target_size=(224, 224)) # 파일 변환 사이즈만 알려주면 됨\n",
    "    img_array = img_to_array(img) # 읽은 이미지를 Numpy 배열로변환 (224, 224, 3) 크기.\n",
    "    img_array = np.expand_dims(img_array, axis=0) # 배열 차원 확장 (1, 224, 224, 3)\n",
    "\n",
    "    # 이미지 데이터 전처리\n",
    "    img_array = preprocess_input(img_array)\n",
    "\n",
    "    # 예측\n",
    "    predictions = model.predict(img_array)\n",
    "    print(predictions)\n",
    "\n",
    "    # 예측 결과\n",
    "    predicted_class = np.argmax(predictions, axis=1)\n",
    "    confidence = np.max(predictions, axis=1)\n",
    "\n",
    "    # 클래스 인덱스를 클래스명으로 변환\n",
    "    pred = answer_class[predicted_class[0]]\n",
    "    result.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['result'] = result\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('01073002902_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
